<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="keywords" content="VinEye, Monitoring, VDD, Precision Viticulture, Agronomy 4.0">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VinEye</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VinEye</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://molnarszilard.github.io/">Szilard Molnar</a>,</span>
            <span class="author-block">
              <a href="http://rocon.utcluj.ro/~levente">Levente Tamas</a></span>
              <span class="author-block">
                <a>, and others</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Technical University of Cluj-Napoca, Memorandumului 28, 400114 Romania</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://www.sciencedirect.com/science/article/pii/S0957417423033067?dgcid=author"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://github.com/tamaslevente/vineye"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center><img src="static/images/vineye_overview.png" alt="Alternative Text" class="center"></center>
      <!-- <center><img src="static/images/intro_0.png" alt="Alternative Text"  width="70%" class="center"></center> -->
      <h2 class="subtitle has-text-centered">
        Monitoring vineyards using UAVs and UGVs based on computer vision, deep learning, and robotics. 
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Dataset. -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Dataset</h2>
          <center><img src="static/images/vineyardmap.png" alt="Alternative Text" width="80%" class="center"></center>
          <div class="content has-text-justified">
            <p>
              Vine disease detection is considered to be one of the most crucial components in precision viticulture. It serves as an input for several further modules, including mapping, automatic treatment and spraying devices. In the last few years, several approaches were proposed for detecting vine disease based on indoor laboratory conditions or on large-scale satellite images, integrated with machine learning tools. However, these methods have several limitations, including laboratory-specific conditions or limited visibility into plant-related diseases. To overcome these limitations, we propose a low-altitude drone flight approach through which we generate a comprehensive dataset about various vine diseases from a large-scale dataset in Europe. The dataset contains typical diseases such as downy mildew or black rot affecting the large variety of grapes including Muscat of Hamburg, Alphonse Lavallée, Grasă de Cotnari, Rkatsiteli, Napoca, Pinot blanc, Pinot gris, Chambourcin, Fetească regală, Sauvignon blanc, Muscat Ottonel, Merlot, and Seyve-Villard 18402. The data set contains 10,000 images and more than 100,000 annotated leaves, which were verified by viticulture specialists. Grape bunches are also annotated for yield estimation.
              Further, we tested state-of-the-art detection methods on this dataset focusing also on viable solutions on embedded devices, including Android-based phones or Nvidia Jetson boards with GPU.
            </p>
            <center><img src="static/images/July04_USAMV_IMG_7427_f_05000_cropped.png" alt="Alternative Text" width="80%" class="center"></center>
            <p>
              Close range unmanned aerial vehicle image acquisition.
            </p>
            <center><img src="static/images/Cluj_Aug03_DJI_0562_f_04600_fpfn.jpg" alt="Alternative Text" width="80%" class="center"></center>
            <p>
              We used Roboflow API to manually annotated the images, marking all the bacterial and fungicidal diseases on the leaves, besides the visible grape bunches (regardless of their health status).
              Then, we evaluated the quality of the dataset using 
              <a href="https://github.com/ultralytics/ultralytics">YOLOv8</a> and <a href="https://github.com/molnarszilard/canopy_segmentation">FPN</a>. An example of the YOLOv8 detection:
            </p>
          </div>

        </div>
      </div>
    </div>
    <!--/ Dataset. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Segmentation. -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Feature Pyramid Network based Proximal Vine Canopy Segmentation</h2>
          <center><img src="static/images/July04_USAMV_DJI_0231_f_01500_annotations.png" alt="Alternative Text" width="80%" class="center"></center>
          <div class="content has-text-justified">
            <p>
              With the widening of the Agriculture 4.0 era, the use of autonomous robots in the agriculture field is becoming a priority.
              The key component of such an autonomous, often multi-robot system is the perception of the environment, which is based on 2D and 3D cameras. 
              A base processing part of the 2D images is the segmentation of different zones in the images. 
              This is the case also in the vineyards where in order to process complex plant canopies, segmenting the parts of the image containing the area of interest is a part of the pre-processing chain. 
              In this work, we present a Feature Pyramid Network-based grape canopy segmentation method, which has great potential to create a segmentation mask, containing only the leaves and fruits of interest. 
              We conducted our tests in different vineyards and we also obtained the above state-of-the-art segmentation results on public and custom datasets. 
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Segmentation. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Segmentation. -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Segmentation Methods Evaluation on Grapevine Leaf Diseases</h2>
          <!-- <center><img src="static/images/July04_USAMV_DJI_0231_f_01500_annotations.png" alt="Alternative Text" width="80%" class="center"></center> -->
          <div class="content has-text-justified">
            <p>
              The problem of vine disease detection (VDD) was
              addressed in a number of research papers, however, a generic
              solution is not yet available for this task in the community.
              The region of interest segmentation and object detection tasks
              are often complementary. A similar situation is encountered
              in VDD applications as well, in which crop or leaf detection
              can be done via instance segmentation techniques as well. The
              focus of this work is to validate the most suitable methods
              from the main literature on vine leaf segmentation and disease
              detection on a custom dataset containing leaves both from the
              laboratory environment and cropped from images in the field. We
              tested five promising methods including the Otsu’s thresholding,
              Mask R-CNN, MobileNet, SegNet, and Feature Pyramid Network
              variants. The results of the comparison are available in Table I
              summarizing the accuracy and runtime of different methods. 
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Segmentation. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@Article{molnar2023fpncanopy,
      author  = {Szil{\'a}rd Moln{\'a}r and Barna Keresztes and Levente Tam{\'a}s},
      journal = {IFAC-PapersOnLine},
      title   = {{Feature Pyramid Network based Proximal Vine Canopy Segmentation}},
      year    = {2023},
      note    = {22nd IFAC World Congress},
      number  = {2},
      pages   = {8920--8925},
      volume  = {56},
      doi     = {10.1016/j.ifacol.2023.10.097},
    }
    </code></pre>

    <pre><code>@InProceedings{molnar2023segmentationmethodsevaluation,
      author    = {Szil{\'{a}}rd Moln{\'{a}}r and Levente Tam{\'{a}}s},
      booktitle = {Proceedings of the 18th Conference on Computer Science and Intelligence Systems, FedCSIS 2023, Warsaw, Poland, September 17-20, 2023},
      title     = {{Segmentation Methods Evaluation on Grapevine Leaf Diseases}},
      year      = {2023},
      editor    = {Maria Ganzha and Leszek A. Maciaszek and Marcin Paprzycki and Dominik Slezak},
      pages     = {1081--1085},
      series    = {Annals of Computer Science and Information Systems},
      volume    = {35},
      doi       = {10.15439/2023F7053},
    }    
    </code></pre>

  </div>
</section>

</body>
</html>
